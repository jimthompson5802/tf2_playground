# Experiments with TF Optimizers

Work inspired by J. Brownlee's [blog posting](https://machinelearningmastery.com/gradient-descent-optimization-with-nadam-from-scratch/)

Notebook `optimizer_playground.ipynb` provides a means to see how TF's different optimizers behave.  It should be noted the "loss values" generated in the notebook are for demonstration purposes only and not intended portray actual loss values encountered during deep neural network training.

## Simple Loss Example
Illustrative Loss Surface

![Simple Example Loss Surface](./images/simple/surface_plot.png)

Contour plot

![Simple Example Loss Contour Plot](./images/simple/contour_plot.png)

Comparision of TF Optimizers on the Simple Loss Example

![Simple Example Optimizer Behavior](./images/simple/optimizer_plots.png)


## More Complex Loss Example
Illustrative Loss Surface

![Complex Example Loss Surface](./images/multi-modal/surface_plot.png)

Contour plot

![Complex Example Loss Contour Plot](./images/multi-modal/contour_plot.png)

Comparision of TF Optimizers on the Complex Loss Example

![Complex Example Optimizer Behavior](./images/multi-modal/optimizer_plots.png)

